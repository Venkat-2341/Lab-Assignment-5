{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import augly.image as imaugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train and test...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data\\\\test\\\\cats'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m             copyfile(src, dst)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplitting dataset into train and test...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[43msplit_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_train_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_split_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Step 2: Define data augmentation functions\u001b[39;00m\n\u001b[0;32m     44\u001b[0m augmentation_functions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     45\u001b[0m     imaugs\u001b[38;5;241m.\u001b[39mRandomBlur(min_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, max_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.0\u001b[39m),\n\u001b[0;32m     46\u001b[0m     imaugs\u001b[38;5;241m.\u001b[39mRandomRotation(min_degrees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m, max_degrees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \n\u001b[0;32m     57\u001b[0m ]\n",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m, in \u001b[0;36msplit_dataset\u001b[1;34m(source_dir, train_dir, test_dir, split_ratio)\u001b[0m\n\u001b[0;32m     24\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_dir, \u001b[38;5;28mcls\u001b[39m), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m src_cls_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_dir, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_cls_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(src_cls_dir, f))]\n\u001b[0;32m     27\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(files)\n\u001b[0;32m     28\u001b[0m split_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m*\u001b[39m split_ratio)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data\\\\test\\\\cats'"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Define paths\n",
    "data_dir = 'data'\n",
    "source_dir = os.path.join(data_dir, 'test')  # Assuming Kaggle's test folder is placed here\n",
    "original_train_dir = os.path.join(data_dir, 'train_original')\n",
    "augmented_train_dir = os.path.join(data_dir, 'train_augmented')\n",
    "test_split_dir = os.path.join(data_dir, 'test_split')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(original_train_dir, exist_ok=True)\n",
    "os.makedirs(augmented_train_dir, exist_ok=True)\n",
    "os.makedirs(test_split_dir, exist_ok=True)\n",
    "\n",
    "# Step 1: Split the dataset into train and test\n",
    "def split_dataset(source_dir, train_dir, test_dir, split_ratio=0.8):\n",
    "    classes = ['cats', 'dogs']\n",
    "    for cls in classes:\n",
    "        os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
    "        src_cls_dir = os.path.join(source_dir, cls)\n",
    "        files = [f for f in os.listdir(src_cls_dir) if os.path.isfile(os.path.join(src_cls_dir, f))]\n",
    "        random.shuffle(files)\n",
    "        split_idx = int(len(files) * split_ratio)\n",
    "        train_files = files[:split_idx]\n",
    "        test_files = files[split_idx:]\n",
    "        for f in train_files:\n",
    "            src = os.path.join(src_cls_dir, f)\n",
    "            dst = os.path.join(train_dir, cls, f)\n",
    "            copyfile(src, dst)\n",
    "        for f in test_files:\n",
    "            src = os.path.join(src_cls_dir, f)\n",
    "            dst = os.path.join(test_dir, cls, f)\n",
    "            copyfile(src, dst)\n",
    "\n",
    "print(\"Splitting dataset into train and test...\")\n",
    "split_dataset(source_dir, original_train_dir, test_split_dir, split_ratio=0.8)\n",
    "\n",
    "# Step 2: Define data augmentation functions\n",
    "augmentation_functions = [\n",
    "    imaugs.RandomBlur(min_radius=1.0, max_radius=3.0),\n",
    "    imaugs.RandomRotation(min_degrees=-30, max_degrees=30),\n",
    "    imaugs.RandomPixelization(min_ratio=0.1, max_ratio=0.5),\n",
    "    imaugs.HFlip(p=1.0),\n",
    "    imaugs.VFlip(p=1.0),\n",
    "    imaugs.Grayscale(p=1.0),\n",
    "    imaugs.ColorJitter(brightness_factor=0.5, contrast_factor=0.5, saturation_factor=0.5),\n",
    "    \n",
    "    imaugs.RandomBrightness(min_factor=0.1, max_factor=0.5),\n",
    "    \n",
    "    imaugs.RandomNoise(),\n",
    "\n",
    "]\n",
    "\n",
    "def custom_augment(image_path, output_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    selected_augs = random.sample(augmentation_functions, 3)\n",
    "    aug = imaugs.Compose(selected_augs)\n",
    "    augmented_image = aug(image)\n",
    "    augmented_image.save(output_path)\n",
    "\n",
    "# Step 3: Generate augmented images\n",
    "def generate_augmented_images(train_dir, augmented_train_dir, num_augmented=2):\n",
    "    classes = ['cats', 'dogs']\n",
    "    for cls in classes:\n",
    "        cls_dir = os.path.join(train_dir, cls)\n",
    "        augmented_cls_dir = os.path.join(augmented_train_dir, cls)\n",
    "        os.makedirs(augmented_cls_dir, exist_ok=True)\n",
    "        # Copy original images\n",
    "        for filename in os.listdir(cls_dir):\n",
    "            if filename.startswith('.'):\n",
    "                continue\n",
    "            src = os.path.join(cls_dir, filename)\n",
    "            dst = os.path.join(augmented_cls_dir, filename)\n",
    "            copyfile(src, dst)\n",
    "        # Generate augmented images\n",
    "        for filename in os.listdir(cls_dir):\n",
    "            if filename.startswith('.'):\n",
    "                continue\n",
    "            src_path = os.path.join(cls_dir, filename)\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            for i in range(num_augmented):\n",
    "                output_path = os.path.join(augmented_cls_dir, f\"{base}_aug{i}{ext}\")\n",
    "                custom_augment(src_path, output_path)\n",
    "\n",
    "print(\"Generating augmented images...\")\n",
    "generate_augmented_images(original_train_dir, augmented_train_dir, num_augmented=2)\n",
    "\n",
    "# Step 4: Plot dataset statistics\n",
    "def plot_counts(original_dir, augmented_dir):\n",
    "    classes = ['cats', 'dogs']\n",
    "    original_counts = {}\n",
    "    augmented_counts = {}\n",
    "    for cls in classes:\n",
    "        original_cls = os.path.join(original_dir, cls)\n",
    "        augmented_cls = os.path.join(augmented_dir, cls)\n",
    "        original_counts[cls] = len(os.listdir(original_cls))\n",
    "        augmented_counts[cls] = len(os.listdir(augmented_cls))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(classes))\n",
    "    plt.bar(index, [original_counts[cls] for cls in classes], bar_width, label='Original')\n",
    "    plt.bar(index + bar_width, [augmented_counts[cls] for cls in classes], bar_width, label='Augmented')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Dataset Statistics Before and After Augmentation')\n",
    "    plt.xticks(index + bar_width/2, classes)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dataset_stats.png')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Plotting dataset statistics...\")\n",
    "plot_counts(original_train_dir, augmented_train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
